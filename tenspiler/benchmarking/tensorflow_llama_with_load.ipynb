{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-11 13:00:24.564225: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-11 13:00:24.668583: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-11 13:00:24.668617: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-11 13:00:24.683533: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-11 13:00:24.720523: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-11 13:00:25.198128: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = './vicuna_weight.h5'\n",
    "\n",
    "weights = []\n",
    "w_input = []\n",
    "attn_weights = []\n",
    "aw_input = []\n",
    "q_weights = []\n",
    "k_weights = []\n",
    "\n",
    "with h5py.File(weights_path, 'r') as weight_file:\n",
    "    for layer_name in weight_file:\n",
    "        w = np.squeeze(np.array(weight_file[layer_name])).astype(np.float32)\n",
    "        if \"model\" in layer_name and \"embed_tokens\" not in layer_name and \"layernorm\" not in layer_name:\n",
    "            weights.append(w)\n",
    "            w_input.append(rng.random(w.shape, dtype = np.float32))\n",
    "        if \"attn\" in layer_name:\n",
    "            attn_weights.append(w)\n",
    "            aw_input.append(rng.random(w.shape[1], dtype = np.float32))\n",
    "            if \"q_proj\" in layer_name:\n",
    "                q_weights.append(w)\n",
    "            if \"k_proj\" in layer_name:\n",
    "                k_weights.append(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer(input1, input2, f, runner):\n",
    "    runs = 10\n",
    "    times = []\n",
    "    for _ in range(runs):\n",
    "        times.append(runner(input1, input2, f))\n",
    "    times = np.array(times)\n",
    "    print(f\"{runner.__name__[:-6]}tensorflow_with_load\")\n",
    "    print(f\"{np.average(times)}ms +/- {np.std(times)}ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elewise_mul_tf(input1, input2, hidden_dim):\n",
    "    return tf.multiply(input1[:hidden_dim], input2[:hidden_dim])\n",
    "\n",
    "def elewise_mul_runner(inputs1, inputs2, f=None):\n",
    "    total_time = 0\n",
    "    for i in range(len(inputs1)):\n",
    "        input1 = inputs1[i].flatten()\n",
    "        input2 = inputs2[i].flatten()\n",
    "        hd = len(input1)\n",
    "        with tf.device('/CPU:0'):\n",
    "            inp1 = tf.convert_to_tensor(input1, np.float32) \n",
    "            inp2 = tf.convert_to_tensor(input2, np.float32) \n",
    "            hidden_dim = tf.constant(hd, dtype=tf.int32)\n",
    "        with tf.device('/GPU:0'):\n",
    "            start_time = time.perf_counter()\n",
    "            inp1 = tf.identity(inp1)\n",
    "            inp2 = tf.identity(inp2)\n",
    "            hidden_dim = tf.identity(hidden_dim)\n",
    "            res = elewise_mul_tf(inp1, inp2, hidden_dim)\n",
    "        with tf.device('/CPU:0'):\n",
    "            res = tf.identity(res)\n",
    "            end_time = time.perf_counter()\n",
    "        del inp2\n",
    "        del inp1\n",
    "        total_time += (end_time - start_time) * 1000\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul_tf(weight, input):\n",
    "    return tf.linalg.matvec(weight, input)\n",
    "\n",
    "def matmul_runner(weights, inputs, f=None):\n",
    "    total_time = 0\n",
    "    for i in range(len(inputs)):\n",
    "        weight = weights[i]\n",
    "        input = inputs[i]\n",
    "        with tf.device('/CPU:0'):\n",
    "            w = tf.convert_to_tensor(weight, np.float32) \n",
    "            inp = tf.convert_to_tensor(input, np.float32) \n",
    "        with tf.device('/GPU:0'):\n",
    "            start_time = time.perf_counter()\n",
    "            w = tf.identity(w)\n",
    "            inp = tf.identity(inp)\n",
    "            res = matmul_tf(w, inp)\n",
    "        with tf.device('/CPU:0'):\n",
    "            res = tf.identity(res)\n",
    "            end_time = time.perf_counter()\n",
    "        del inp\n",
    "        del w\n",
    "        total_time += (end_time - start_time) * 1000\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiquery_attention_part1_tf(token_position, head, head_size, key_cache_layer, q):\n",
    "    return tf.linalg.matvec(key_cache_layer[:token_position][:, (head * head_size):(head * head_size) + head_size], q[(head * head_size):(head * head_size) + head_size])/tf.sqrt(tf.cast(head_size * 1, tf.float32))\n",
    "\n",
    "def multiquery_attention_part1_runner(k_matrixes, q_matrixes, f=None):\n",
    "    total_time = 0\n",
    "    for i in range(len(k_matrixes)):\n",
    "        k_matrix = k_matrixes[i]\n",
    "        q_matrix = q_matrixes[i]\n",
    "        token_position = k_matrix.shape[0] - 1\n",
    "\n",
    "        num_head = 32\n",
    "        head = int(rng.integers(low=0, high=num_head))\n",
    "        head_size = k_matrix.shape[0] // num_head\n",
    "\n",
    "\n",
    "        q_matrix = q_matrix.flatten()\n",
    "        with tf.device('/CPU:0'):\n",
    "            key_cache_layer = tf.convert_to_tensor(k_matrix, np.float32) \n",
    "            q = tf.convert_to_tensor(q_matrix, np.float32) \n",
    "        with tf.device('/GPU:0'):\n",
    "            start_time = time.perf_counter()\n",
    "            key_cache_layer = tf.identity(key_cache_layer) \n",
    "            q = tf.identity(q) \n",
    "            res = multiquery_attention_part1_tf(token_position, head, head_size, key_cache_layer, q)\n",
    "        with tf.device('/CPU:0'):\n",
    "            res = tf.identity(res)\n",
    "            end_time = time.perf_counter()\n",
    "        del key_cache_layer\n",
    "        del q\n",
    "        total_time += (end_time - start_time) * 1000\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiquery_attention_part2_tf(token_position, head, head_size, key_cache_layer, attention):\n",
    "    return tf.linalg.matvec(tf.transpose(key_cache_layer[:token_position+1][:, (head * head_size):(head * head_size) + head_size]), attention[:token_position+1])\n",
    "\n",
    "def multiquery_attention_part2_runner(k_matrixes, q_matrixes, f=None):\n",
    "    total_time = 0\n",
    "    for i in range(len(k_matrixes)):\n",
    "        k_matrix = k_matrixes[i]\n",
    "        q_matrix = q_matrixes[i]\n",
    "        token_position = k_matrix.shape[0] - 1\n",
    "\n",
    "        num_head = 32\n",
    "        head = int(rng.integers(low=0, high=num_head))\n",
    "        head_size = k_matrix.shape[0] // num_head\n",
    "\n",
    "        q_matrix = q_matrix.flatten()\n",
    "        with tf.device('/CPU:0'):\n",
    "            key_cache_layer = tf.convert_to_tensor(k_matrix, np.float32) \n",
    "            q = tf.convert_to_tensor(q_matrix, np.float32) \n",
    "            attention = multiquery_attention_part1_tf(token_position, head, head_size, key_cache_layer, q)\n",
    "            attention = tf.concat((attention, tf.constant([0.0])), axis=0)\n",
    "        with tf.device('/GPU:0'):\n",
    "            start_time = time.perf_counter()\n",
    "            key_cache_layer = tf.identity(key_cache_layer) \n",
    "            attention = tf.identity(attention)\n",
    "            res = multiquery_attention_part2_tf(token_position, head, head_size, key_cache_layer, attention)\n",
    "        with tf.device('/CPU:0'):\n",
    "            res = tf.identity(res)\n",
    "            end_time = time.perf_counter()\n",
    "        del key_cache_layer\n",
    "        del attention\n",
    "        total_time += (end_time - start_time) * 1000\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsnorm_part1_tf(input, weight):\n",
    "    return tf.reduce_sum(tf.multiply(input, input))\n",
    "\n",
    "def rmsnorm_part1_runner(weights, inputs, f=None):\n",
    "    total_time = 0\n",
    "    for i in range(len(inputs)):\n",
    "        input = inputs[i].flatten()\n",
    "        weight = weights[i].flatten()\n",
    "        with tf.device('/CPU:0'):\n",
    "            w = tf.convert_to_tensor(weight, np.float32) \n",
    "            inp = tf.convert_to_tensor(input, np.float32) \n",
    "        with tf.device('/GPU:0'):\n",
    "            start_time = time.perf_counter()\n",
    "            w = tf.identity(w)\n",
    "            inp = tf.identity(inp)\n",
    "            res = rmsnorm_part1_tf(inp, w)\n",
    "        with tf.device('/CPU:0'):\n",
    "            res = tf.identity(res)\n",
    "            end_time = time.perf_counter()\n",
    "        del w\n",
    "        del inp\n",
    "        total_time += (end_time - start_time) * 1000\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsnorm_part2_tf(input, weight, ss):\n",
    "    return tf.multiply((1 / tf.sqrt(tf.cast((ss/tf.size(input, tf.float32)) + 1, tf.float32))), tf.multiply(input, weight))\n",
    "\n",
    "def rmsnorm_part2_runner(weights, inputs, f=None):\n",
    "    total_time = 0\n",
    "    for i in range(len(inputs)):\n",
    "        input = inputs[i].flatten()\n",
    "        weight = weights[i].flatten()\n",
    "        ssum = np.sum(input * input)\n",
    "        with tf.device('/CPU:0'):\n",
    "            w = tf.convert_to_tensor(weight, np.float32) \n",
    "            inp = tf.convert_to_tensor(input, np.float32) \n",
    "            ss = tf.convert_to_tensor(ssum, np.float32)\n",
    "        with tf.device('/GPU:0'):\n",
    "            start_time = time.perf_counter()\n",
    "            w = tf.identity(w)\n",
    "            inp = tf.identity(inp)\n",
    "            ss = tf.identity(ss)\n",
    "            res = rmsnorm_part2_tf(inp, w, ss)\n",
    "        with tf.device('/CPU:0'):\n",
    "            res = tf.identity(res)\n",
    "            end_time = time.perf_counter()\n",
    "        del w\n",
    "        del inp\n",
    "        total_time += (end_time - start_time) * 1000\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silu_tf(input, hidden_dim):\n",
    "    return tf.multiply(tf.divide(1, (tf.exp(0 - input[:hidden_dim]) + 1)), input[:hidden_dim])\n",
    "\n",
    "def silu_runner(inputs, _, f=None):\n",
    "    total_time = 0\n",
    "    for i in range(len(inputs)):\n",
    "        input = inputs[i].flatten()\n",
    "        hd = len(input)\n",
    "        with tf.device('/CPU:0'):\n",
    "            inp = tf.convert_to_tensor(input, np.float32)\n",
    "            hidden_dim = tf.constant(hd, dtype=tf.int32)\n",
    "        with tf.device('/GPU:0'):\n",
    "            start_time = time.perf_counter()\n",
    "            inp = tf.identity(inp)\n",
    "            hidden_dim = tf.identity(hidden_dim)\n",
    "            res = silu_tf(inp, hidden_dim)\n",
    "        with tf.device('/CPU:0'):\n",
    "            res = tf.identity(res)\n",
    "            end_time = time.perf_counter()\n",
    "        del inp\n",
    "        total_time += (end_time - start_time) * 1000\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_part1_tf(input, max_pos):\n",
    "    return tf.reduce_max(input[:max_pos])\n",
    "\n",
    "def softmax_part1_runner(inputs, _, f=None):\n",
    "    total_time = 0\n",
    "    for i in range(len(inputs)):\n",
    "        input = inputs[i].flatten()\n",
    "        mp = len(input)\n",
    "        with tf.device('/CPU:0'):\n",
    "            inp = tf.convert_to_tensor(input, np.float32)\n",
    "            max_pos = tf.constant(mp, dtype=tf.int32)\n",
    "        with tf.device('/GPU:0'):\n",
    "            start_time = time.perf_counter()\n",
    "            inp = tf.identity(inp)\n",
    "            max_pos = tf.identity(max_pos) \n",
    "            res = softmax_part1_tf(inp, max_pos)\n",
    "        with tf.device('/CPU:0'):\n",
    "            res = tf.identity(res)\n",
    "            end_time = time.perf_counter()\n",
    "        del inp\n",
    "        total_time += (end_time - start_time) * 1000\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_part2_tf(input, max_pos, max_val):\n",
    "    return tf.exp(tf.cast(input[:max_pos] - max_val, tf.float32))\n",
    "\n",
    "def softmax_part2_runner(inputs, _, f=None):\n",
    "    total_time = 0\n",
    "    for i in range(len(inputs)):\n",
    "        input = inputs[i].flatten()\n",
    "        mp = len(input)\n",
    "        with tf.device('/CPU:0'):\n",
    "            inp = tf.convert_to_tensor(input, np.float32)\n",
    "            max_pos = tf.constant(mp, dtype=tf.int32)\n",
    "            max_val = tf.convert_to_tensor(np.max(input[:mp]), np.float32)\n",
    "        with tf.device('/GPU:0'):\n",
    "            start_time = time.perf_counter()\n",
    "            inp = tf.identity(inp)\n",
    "            max_pos = tf.identity(max_pos) \n",
    "            max_val = tf.identity(max_val)\n",
    "            res = softmax_part2_tf(inp, max_pos, max_val)\n",
    "        with tf.device('/CPU:0'):\n",
    "            res = tf.identity(res)\n",
    "            end_time = time.perf_counter()\n",
    "        del inp\n",
    "        total_time += (end_time - start_time) * 1000\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_part3_tf(output, max_pos):\n",
    "    return tf.reduce_sum(output[:max_pos])\n",
    "\n",
    "def softmax_part3_runner(inputs, _, f=None):\n",
    "    total_time = 0\n",
    "    for i in range(len(inputs)):\n",
    "        input = inputs[i].flatten()\n",
    "        mp = len(input)\n",
    "        output = np.exp(input[:mp]-np.max(input[:mp]))\n",
    "        with tf.device('/CPU:0'):\n",
    "            outp = tf.convert_to_tensor(output, np.float32)\n",
    "            max_pos = tf.constant(mp, dtype=tf.int32)\n",
    "        with tf.device('/GPU:0'):\n",
    "            start_time = time.perf_counter()\n",
    "            outp = tf.identity(outp)\n",
    "            max_pos = tf.identity(max_pos) \n",
    "            res = softmax_part3_tf(outp, max_pos)\n",
    "        with tf.device('/CPU:0'):\n",
    "            res = tf.identity(res)\n",
    "            end_time = time.perf_counter()\n",
    "        del outp\n",
    "        total_time += (end_time - start_time) * 1000\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_part4_tf(unnormalized_output, max_pos, sum):\n",
    "    return unnormalized_output[:max_pos]/sum\n",
    "\n",
    "def softmax_part4_runner(inputs, _, f=None):\n",
    "    total_time = 0\n",
    "    for i in range(len(inputs)):\n",
    "        input = inputs[i].flatten()\n",
    "        mp = len(input)\n",
    "        output = np.exp(input[:mp]-np.max(input[:mp]))\n",
    "        s = np.sum(output[:mp])\n",
    "        with tf.device('/CPU:0'):\n",
    "            outp = tf.convert_to_tensor(output, np.float32)\n",
    "            max_pos = tf.constant(mp, dtype=tf.int32)\n",
    "            sum = tf.convert_to_tensor(s, np.float32)\n",
    "        with tf.device('/GPU:0'):\n",
    "            start_time = time.perf_counter()\n",
    "            outp = tf.identity(outp)\n",
    "            max_pos = tf.identity(max_pos) \n",
    "            sum = tf.identity(sum)\n",
    "            res = softmax_part4_tf(outp, max_pos, sum)\n",
    "        with tf.device('/CPU:0'):\n",
    "            res = tf.identity(res)\n",
    "            end_time = time.perf_counter()\n",
    "        del outp\n",
    "        total_time += (end_time - start_time) * 1000\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-11 13:00:32.444742: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_COMPAT_NOT_SUPPORTED_ON_DEVICE: forward compatibility was attempted on non supported HW\n",
      "2024-01-11 13:00:32.445134: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:129] retrieving CUDA diagnostic information for host: colinc\n",
      "2024-01-11 13:00:32.445136: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:136] hostname: colinc\n",
      "2024-01-11 13:00:32.445176: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:159] libcuda reported version is: 535.146.2\n",
      "2024-01-11 13:00:32.445184: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:163] kernel reported version is: 535.129.3\n",
      "2024-01-11 13:00:32.445186: E external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:244] kernel version 535.129.3 does not match DSO version 535.146.2 -- cannot find working devices in this configuration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elewise_mul_tensorflow_with_load\n",
      "284.40932482481ms +/- 9.906515523455361ms\n"
     ]
    }
   ],
   "source": [
    "timer(weights, w_input, None, elewise_mul_runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matmul_tensorflow_with_load\n",
      "80.03217247314751ms +/- 10.781710929610968ms\n"
     ]
    }
   ],
   "source": [
    "timer(attn_weights, aw_input, None, matmul_runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiquery_attention_part1_tensorflow_with_load\n",
      "21.66841602884233ms +/- 2.439472383029676ms\n"
     ]
    }
   ],
   "source": [
    "timer(k_weights, q_weights, None, multiquery_attention_part1_runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiquery_attention_part2_tensorflow_with_load\n",
      "7.8336704056710005ms +/- 2.134037043607374ms\n"
     ]
    }
   ],
   "source": [
    "timer(k_weights, q_weights, None, multiquery_attention_part2_runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmsnorm_part1_tensorflow_with_load\n",
      "450.7356496527791ms +/- 2.241457025084523ms\n"
     ]
    }
   ],
   "source": [
    "timer(weights, w_input, None, rmsnorm_part1_runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmsnorm_part2_tensorflow_with_load\n",
      "453.855360718444ms +/- 4.165485436942907ms\n"
     ]
    }
   ],
   "source": [
    "timer(weights, w_input,None, rmsnorm_part2_runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "silu_tensorflow_with_load\n",
      "820.5589587334543ms +/- 1.379051373853ms\n"
     ]
    }
   ],
   "source": [
    "timer(weights, None, None, silu_runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax_part1_tensorflow_with_load\n",
      "45.10223506949842ms +/- 7.360041188113004ms\n"
     ]
    }
   ],
   "source": [
    "timer(attn_weights, None, None, softmax_part1_runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax_part2_tensorflow_with_load\n",
      "128.38186309672892ms +/- 2.414270580669231ms\n"
     ]
    }
   ],
   "source": [
    "timer(attn_weights, None, None, softmax_part2_runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax_part3_tensorflow_with_load\n",
      "40.287359757348895ms +/- 0.34765948613478004ms\n"
     ]
    }
   ],
   "source": [
    "timer(attn_weights, None, None, softmax_part3_runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax_part4_tensorflow_with_load\n",
      "97.43978586047888ms +/- 0.9419789740914143ms\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "timer(attn_weights, None, None, softmax_part4_runner)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
