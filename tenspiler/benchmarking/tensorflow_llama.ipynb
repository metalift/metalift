{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-12 18:46:13.377137: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-12 18:46:13.483837: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-12 18:46:13.483868: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-12 18:46:13.498870: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-12 18:46:13.537414: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-12 18:46:14.008466: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = './vicuna_weight.h5'\n",
    "\n",
    "weights = []\n",
    "w_input = []\n",
    "attn_weights = []\n",
    "aw_input = []\n",
    "q_weights = []\n",
    "k_weights = []\n",
    "\n",
    "with h5py.File(weights_path, 'r') as weight_file:\n",
    "    for layer_name in weight_file:\n",
    "        w = np.squeeze(np.array(weight_file[layer_name])).astype(np.float32)\n",
    "        if \"model\" in layer_name and \"embed_tokens\" not in layer_name and \"layernorm\" not in layer_name:\n",
    "            weights.append(w)\n",
    "            w_input.append(rng.random(w.shape, dtype = np.float32))\n",
    "        if \"attn\" in layer_name:\n",
    "            attn_weights.append(w)\n",
    "            aw_input.append(rng.random(w.shape[1], dtype = np.float32))\n",
    "            if \"q_proj\" in layer_name:\n",
    "                q_weights.append(w)\n",
    "            if \"k_proj\" in layer_name:\n",
    "                k_weights.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer(input1, input2, f, runner):\n",
    "    runs = 10\n",
    "    times = []\n",
    "    for _ in range(runs):\n",
    "        times.append(runner(input1, input2, f))\n",
    "    times = np.array(times)\n",
    "    print(f\"{runner.__name__[:-6]}tensorflow\")\n",
    "    print(f\"{np.average(times)}ms +/- {np.std(times)}ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_part4_tf(input1, input2, hidden_dim):\n",
    "    return (input1[:hidden_dim]) * (input2[:hidden_dim])\n",
    "\n",
    "def transformer_part4_runner(inputs1, inputs2, f=None):\n",
    "    total_time = 0\n",
    "    for i in range(len(inputs1)):\n",
    "        input1 = inputs1[i].flatten()\n",
    "        input2 = inputs2[i].flatten()\n",
    "        hd = len(input1)\n",
    "        with tf.device('/GPU:0'):\n",
    "            inp1 = tf.convert_to_tensor(input1, np.float32) \n",
    "            inp2 = tf.convert_to_tensor(input2, np.float32) \n",
    "            hidden_dim = tf.constant(hd, dtype=tf.int32)\n",
    "            \n",
    "            start_time = time.perf_counter()\n",
    "            transformer_part4_tf(inp1, inp2, hidden_dim)\n",
    "            end_time = time.perf_counter()\n",
    "            del inp2\n",
    "            del inp1\n",
    "        total_time += (end_time - start_time) * 1000\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul_tf(weight, input):\n",
    "    return tf.linalg.matvec(weight, input)\n",
    "\n",
    "def matmul_runner(weights, inputs, f=None):\n",
    "    total_time = 0\n",
    "    for i in range(len(inputs)):\n",
    "        weight = weights[i]\n",
    "        input = inputs[i]\n",
    "        with tf.device('/GPU:0'):\n",
    "            w = tf.convert_to_tensor(weight, np.float32) \n",
    "            inp = tf.convert_to_tensor(input, np.float32) \n",
    "        \n",
    "            start_time = time.perf_counter()\n",
    "            matmul_tf(w, inp)\n",
    "            end_time = time.perf_counter()\n",
    "            del inp\n",
    "            del w\n",
    "        total_time += (end_time - start_time) * 1000\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_part1_tf(token_position, head, head_size, key_cache_layer, q):\n",
    "    return (tf.linalg.matvec(key_cache_layer[:token_position][:, (head) * (head_size):(head) * (head_size) + head_size], q[(head) * (head_size):(head) * (head_size) + head_size])) / (tf.sqrt(tf.cast((head_size) * (1), tf.float32)))\n",
    "\n",
    "def transformer_part1_runner(k_matrixes, q_matrixes, f=None):\n",
    "    total_time = 0\n",
    "    for i in range(len(k_matrixes)):\n",
    "        k_matrix = k_matrixes[i]\n",
    "        q_matrix = q_matrixes[i]\n",
    "        token_position = k_matrix.shape[0] - 1\n",
    "\n",
    "        num_head = 32\n",
    "        head = int(rng.integers(low=0, high=num_head))\n",
    "        head_size = k_matrix.shape[0] // num_head\n",
    "\n",
    "        q_matrix = q_matrix.flatten()\n",
    "        with tf.device('/GPU:0'):\n",
    "            key_cache_layer = tf.convert_to_tensor(k_matrix, np.float32) \n",
    "            q = tf.convert_to_tensor(q_matrix, np.float32) \n",
    "            \n",
    "            start_time = time.perf_counter()\n",
    "            transformer_part1_tf(token_position, head, head_size, key_cache_layer, q)\n",
    "            end_time = time.perf_counter()\n",
    "            del key_cache_layer\n",
    "            del q\n",
    "        total_time += (end_time - start_time) * 1000\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_part2_tf(token_position, head, head_size, key_cache_layer, attention):\n",
    "    return tf.linalg.matvec(tf.transpose(key_cache_layer[:(token_position) + (1)][:, (head) * (head_size):(head) * (head_size) + head_size]), attention[:(token_position) + (1)])\n",
    "\n",
    "def transformer_part2_runner(k_matrixes, q_matrixes, f=None):\n",
    "    total_time = 0\n",
    "    for i in range(len(k_matrixes)):\n",
    "        k_matrix = k_matrixes[i]\n",
    "        q_matrix = q_matrixes[i]\n",
    "        token_position = k_matrix.shape[0] - 1\n",
    "\n",
    "        num_head = 32\n",
    "        head = int(rng.integers(low=0, high=num_head))\n",
    "        head_size = k_matrix.shape[0] // num_head\n",
    "        \n",
    "        q_matrix = q_matrix.flatten()\n",
    "        with tf.device('/GPU:0'):\n",
    "            key_cache_layer = tf.convert_to_tensor(k_matrix, np.float32) \n",
    "            q = tf.convert_to_tensor(q_matrix, np.float32) \n",
    "\n",
    "            attention = transformer_part1_tf(token_position, head, head_size, key_cache_layer, q)\n",
    "            attention = tf.concat((attention, tf.constant([0.0])), axis=0)\n",
    "        \n",
    "            start_time = time.perf_counter()\n",
    "            transformer_part2_tf(token_position, head, head_size, key_cache_layer, attention)\n",
    "            end_time = time.perf_counter()\n",
    "            del key_cache_layer\n",
    "            del attention\n",
    "        total_time += (end_time - start_time) * 1000\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsnorm_part1_tf(input, weight):\n",
    "    return tf.reduce_sum((input) * (input))\n",
    "\n",
    "def rmsnorm_part1_runner(weights, inputs, f=None):\n",
    "    total_time = 0\n",
    "    for i in range(len(inputs)):\n",
    "        input = inputs[i].flatten()\n",
    "        weight = weights[i].flatten()\n",
    "        with tf.device('/GPU:0'):\n",
    "            w = tf.convert_to_tensor(weight, np.float32) \n",
    "            inp = tf.convert_to_tensor(input, np.float32) \n",
    "            start_time = time.perf_counter()\n",
    "            rmsnorm_part1_tf(inp, w)\n",
    "            end_time = time.perf_counter()\n",
    "            del w\n",
    "            del inp\n",
    "        total_time += (end_time - start_time) * 1000\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsnorm_part2_tf(input, weight, ss):\n",
    "    return ((1) / (tf.sqrt(tf.cast(((ss) / (tf.size(input, tf.float32))) + (1), tf.float32)))) * ((input) * (weight))\n",
    "\n",
    "def rmsnorm_part2_runner(weights, inputs, f=None):\n",
    "    total_time = 0\n",
    "    for i in range(len(inputs)):\n",
    "        input = inputs[i].flatten()\n",
    "        weight = weights[i].flatten()\n",
    "        ssum = np.sum(input * input)\n",
    "\n",
    "        with tf.device('/GPU:0'):\n",
    "            w = tf.convert_to_tensor(weight, np.float32) \n",
    "            inp = tf.convert_to_tensor(input, np.float32) \n",
    "            ss = tf.convert_to_tensor(ssum, np.float32)\n",
    "\n",
    "            start_time = time.perf_counter()\n",
    "            rmsnorm_part2_tf(inp, w, ss)\n",
    "            end_time = time.perf_counter()\n",
    "            del w\n",
    "            del inp\n",
    "        total_time += (end_time - start_time) * 1000\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_part3_tf(input, hidden_dim):\n",
    "    return (input[:hidden_dim]) * ((1) / ((1) + (tf.exp((0) - (input[:hidden_dim])))))\n",
    "\n",
    "def transformer_part3_runner(inputs, _, f=None):\n",
    "    total_time = 0\n",
    "    for i in range(len(inputs)):\n",
    "        input = inputs[i].flatten()\n",
    "        hd = len(input)\n",
    "        with tf.device('/GPU:0'):\n",
    "            inp = tf.convert_to_tensor(input, np.float32)\n",
    "            hidden_dim = tf.constant(hd, dtype=tf.int32)\n",
    "            start_time = time.perf_counter()\n",
    "            transformer_part3_tf(inp, hidden_dim)\n",
    "            end_time = time.perf_counter()\n",
    "            del inp\n",
    "        total_time += (end_time - start_time) * 1000\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_part1_tf(input, max_pos):\n",
    "    return tf.reduce_max(input[:max_pos])\n",
    "\n",
    "def softmax_part1_runner(inputs, _, f=None):\n",
    "    total_time = 0\n",
    "    for i in range(len(inputs)):\n",
    "        input = inputs[i].flatten()\n",
    "        mp = len(input)\n",
    "        with tf.device('/GPU:0'):\n",
    "            inp = tf.convert_to_tensor(input, np.float32)\n",
    "            max_pos = tf.constant(mp, dtype=tf.int32)\n",
    "            start_time = time.perf_counter()\n",
    "            softmax_part1_tf(inp, max_pos)\n",
    "            end_time = time.perf_counter()\n",
    "            del inp\n",
    "        total_time += (end_time - start_time) * 1000\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_part2_tf(input, max_pos, max_val):\n",
    "    return tf.exp((input[:max_pos]) - (max_val))\n",
    "\n",
    "def softmax_part2_runner(inputs, _, f=None):\n",
    "    total_time = 0\n",
    "    for i in range(len(inputs)):\n",
    "        input = inputs[i].flatten()\n",
    "        mp = len(input)\n",
    "        with tf.device('/GPU:0'):\n",
    "            inp = tf.convert_to_tensor(input, np.float32)\n",
    "            max_pos = tf.constant(mp, dtype=tf.int32)\n",
    "            max_val = tf.convert_to_tensor(np.max(input[:mp]), np.float32)\n",
    "\n",
    "            start_time = time.perf_counter()\n",
    "            softmax_part2_tf(inp, max_pos, max_val)\n",
    "            end_time = time.perf_counter()\n",
    "            del inp\n",
    "        total_time += (end_time - start_time) * 1000\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_part3_tf(output, max_pos):\n",
    "    return tf.reduce_sum(output[:max_pos])\n",
    "\n",
    "def softmax_part3_runner(inputs, _, f=None):\n",
    "    total_time = 0\n",
    "    for i in range(len(inputs)):\n",
    "        input = inputs[i].flatten()\n",
    "        mp = len(input)\n",
    "        output = np.exp(input[:mp]-np.max(input[:mp]))\n",
    "        with tf.device('/GPU:0'):\n",
    "            outp = tf.convert_to_tensor(output, np.float32)\n",
    "            max_pos = tf.constant(mp, dtype=tf.int32)\n",
    "            \n",
    "            start_time = time.perf_counter()\n",
    "            softmax_part3_tf(outp, max_pos)\n",
    "            end_time = time.perf_counter()\n",
    "            del outp\n",
    "        total_time += (end_time - start_time) * 1000\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_part4_tf(unnormalized_output, max_pos, sum):\n",
    "    return (unnormalized_output[:max_pos]) / (sum)\n",
    "\n",
    "def softmax_part4_runner(inputs, _, f=None):\n",
    "    total_time = 0\n",
    "    for i in range(len(inputs)):\n",
    "        input = inputs[i].flatten()\n",
    "        mp = len(input)\n",
    "        output = np.exp(input[:mp]-np.max(input[:mp]))\n",
    "        s = np.sum(output[:mp])\n",
    "        with tf.device('/GPU:0'):\n",
    "            outp = tf.convert_to_tensor(output, np.float32)\n",
    "            max_pos = tf.constant(mp, dtype=tf.int32)\n",
    "            sum = tf.convert_to_tensor(s, np.float32)\n",
    "        \n",
    "            start_time = time.perf_counter()\n",
    "            softmax_part4_tf(outp, max_pos, sum)\n",
    "            end_time = time.perf_counter()\n",
    "            del outp\n",
    "        total_time += (end_time - start_time) * 1000\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-11 14:01:37.078693: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_COMPAT_NOT_SUPPORTED_ON_DEVICE: forward compatibility was attempted on non supported HW\n",
      "2024-01-11 14:01:37.079599: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:129] retrieving CUDA diagnostic information for host: colinc\n",
      "2024-01-11 14:01:37.079602: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:136] hostname: colinc\n",
      "2024-01-11 14:01:37.079769: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:159] libcuda reported version is: 535.146.2\n",
      "2024-01-11 14:01:37.079777: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:163] kernel reported version is: 535.129.3\n",
      "2024-01-11 14:01:37.079779: E external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:244] kernel version 535.129.3 does not match DSO version 535.146.2 -- cannot find working devices in this configuration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elewise_mul_tensorflow\n",
      "263.5096057318151ms +/- 3.5164297249010175ms\n"
     ]
    }
   ],
   "source": [
    "timer(weights, w_input, None, transformer_part4_runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matmul_tensorflow\n",
      "39.25398522987962ms +/- 4.089616600534196ms\n"
     ]
    }
   ],
   "source": [
    "timer(attn_weights, aw_input, None, matmul_runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiquery_attention_part1_tensorflow\n",
      "14.341256799997382ms +/- 19.045698310160926ms\n"
     ]
    }
   ],
   "source": [
    "timer(k_weights, q_weights, None, transformer_part1_runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiquery_attention_part2_tensorflow\n",
      "6.627444829791784ms +/- 2.584835190491138ms\n"
     ]
    }
   ],
   "source": [
    "timer(k_weights, q_weights, None, transformer_part2_runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmsnorm_part1_tensorflow\n",
      "187.19183229841292ms +/- 2.2388239847541787ms\n"
     ]
    }
   ],
   "source": [
    "timer(weights, w_input, None, rmsnorm_part1_runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-12 18:48:16.311962: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-12 18:48:16.378035: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-12 18:48:16.378132: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-12 18:48:16.380121: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-12 18:48:16.380201: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-12 18:48:16.380249: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-12 18:48:16.431631: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-12 18:48:16.431703: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-12 18:48:16.431758: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-12 18:48:16.431803: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14145 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4080, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2024-01-12 18:48:16.740978: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmsnorm_part2_tensorflow\n",
      "46.83127490001198ms +/- 51.92319959088294ms\n"
     ]
    }
   ],
   "source": [
    "timer(weights, w_input,None, rmsnorm_part2_runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "silu_tensorflow\n",
      "24.09263262525201ms +/- 0.9104524488343121ms\n"
     ]
    }
   ],
   "source": [
    "timer(weights, None, None, transformer_part3_runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax_part1_tensorflow\n",
      "9.261212404817343ms +/- 1.3751016449060167ms\n"
     ]
    }
   ],
   "source": [
    "timer(attn_weights, None, None, softmax_part1_runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax_part2_tensorflow\n",
      "7.931538671255112ms +/- 1.1648636374644534ms\n"
     ]
    }
   ],
   "source": [
    "timer(attn_weights, None, None, softmax_part2_runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax_part3_tensorflow\n",
      "8.878669375553727ms +/- 0.16834484359706178ms\n"
     ]
    }
   ],
   "source": [
    "timer(attn_weights, None, None, softmax_part3_runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax_part4_tensorflow\n",
      "9.228620165959ms +/- 0.46544980425183907ms\n"
     ]
    }
   ],
   "source": [
    "timer(attn_weights, None, None, softmax_part4_runner)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
