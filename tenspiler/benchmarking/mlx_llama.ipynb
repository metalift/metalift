{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mlx.core as mx\n",
    "import time\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = './vicuna_weight.h5'\n",
    "\n",
    "weights = []\n",
    "w_input = []\n",
    "attn_weights = []\n",
    "aw_input = []\n",
    "q_weights = []\n",
    "k_weights = []\n",
    "\n",
    "# with h5py.File(weights_path, 'r') as weight_file:\n",
    "#     for layer_name in weight_file:\n",
    "#         w = np.squeeze(np.array(weight_file[layer_name])).astype(np.float32)\n",
    "#         if \"model\" in layer_name and \"embed_tokens\" not in layer_name and \"layernorm\" not in layer_name:\n",
    "#             weights.append(w)\n",
    "#             w_input.append(rng.random(w.shape, dtype = np.float32))\n",
    "#         if \"attn\" in layer_name:\n",
    "#             attn_weights.append(w)\n",
    "#             aw_input.append(rng.random(w.shape[1], dtype = np.float32))\n",
    "#             if \"q_proj\" in layer_name:\n",
    "#                 q_weights.append(w)\n",
    "#             if \"k_proj\" in layer_name:\n",
    "#                 k_weights.append(w)\n",
    "#         if (len(q_weights) > 5 and len(q_weights) == len(k_weights)):\n",
    "#             break\n",
    "\n",
    "with h5py.File(weights_path, 'r') as weight_file:\n",
    "    for layer_name in weight_file:\n",
    "        w = np.squeeze(np.array(weight_file[layer_name])).astype(np.float16)\n",
    "        if \"model\" in layer_name and \"embed_tokens\" not in layer_name and \"layernorm\" not in layer_name:\n",
    "            weights.append(w)\n",
    "            w_input.append(rng.random(w.shape, dtype = np.float32))\n",
    "        if \"attn\" in layer_name:\n",
    "            attn_weights.append(w)\n",
    "            aw_input.append(rng.random(w.shape[1], dtype = np.float32))\n",
    "            if \"q_proj\" in layer_name:\n",
    "                q_weights.append(w)\n",
    "            if \"k_proj\" in layer_name:\n",
    "                k_weights.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer(input1, input2, f, runner):\n",
    "    runs = 10\n",
    "    times = []\n",
    "    for _ in range(runs):\n",
    "        times.append(runner(input1, input2, f))\n",
    "    times = np.array(times)\n",
    "    print(f\"{runner.__name__[:-6]}mlx\")\n",
    "    print(f\"{np.average(times)}ms +/- {np.std(times)}ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_part4_mx(input1, input2, hidden_dim):\n",
    "    return (input1[:hidden_dim]) * (input2[:hidden_dim])\n",
    "\n",
    "# def transformer_part4_runner(inputs1, inputs2, f=None):\n",
    "#     total_time = 0\n",
    "#     for i in range(len(inputs1)):\n",
    "#         input1 = inputs1[i].flatten()\n",
    "#         input2 = inputs2[i].flatten()\n",
    "#         hd = len(input1)\n",
    "\n",
    "#         inp1 = mx.array(input1, mx.float32)\n",
    "#         inp2 = mx.array(input2, mx.float32)\n",
    "#         hidden_dim = hd\n",
    "        \n",
    "#         start_time = time.perf_counter()\n",
    "#         mx.eval(transformer_part4_mx(inp1, inp2, hidden_dim))\n",
    "#         end_time = time.perf_counter()\n",
    "#         del inp2\n",
    "#         del inp1\n",
    "#         total_time += (end_time - start_time) * 1000\n",
    "#     return total_time\n",
    "\n",
    "\n",
    "def transformer_part4_runner(inputs1, inputs2, f=None):\n",
    "    total_time = 0\n",
    "    for i in range(len(inputs1)):\n",
    "        input1 = inputs1[i].flatten().astype(np.float32)\n",
    "        input2 = inputs2[i].flatten().astype(np.float32)\n",
    "        hd = len(input1)\n",
    "\n",
    "        inp1 = mx.array(input1, mx.float32)\n",
    "        inp2 = mx.array(input2, mx.float32)\n",
    "        hidden_dim = hd\n",
    "        \n",
    "        start_time = time.perf_counter()\n",
    "        mx.eval(transformer_part4_mx(inp1, inp2, hidden_dim))\n",
    "        end_time = time.perf_counter()\n",
    "        del inp2\n",
    "        del inp1\n",
    "        total_time += (end_time - start_time) * 1000\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul_mx(weight, input):\n",
    "    return mx.matmul(weight, input)\n",
    "\n",
    "# def matmul_runner(weights, inputs, f=None):\n",
    "#     total_time = 0\n",
    "#     for i in range(len(inputs)):\n",
    "#         weight = weights[i]\n",
    "#         input = inputs[i]\n",
    "\n",
    "#         w = mx.array(weight, mx.float32)\n",
    "#         inp = mx.array(input, mx.float32)\n",
    "        \n",
    "#         start_time = time.perf_counter()\n",
    "#         mx.eval(matmul_mx(w, inp))\n",
    "#         end_time = time.perf_counter()\n",
    "#         del inp\n",
    "#         del w\n",
    "#         total_time += (end_time - start_time) * 1000\n",
    "#     return total_time\n",
    "\n",
    "def matmul_runner(weights, inputs, f=None):\n",
    "    total_time = 0\n",
    "    for i in range(len(inputs)):\n",
    "        weight = weights[i].astype(np.float32)\n",
    "        input = inputs[i].astype(np.float32)\n",
    "\n",
    "        w = mx.array(weight, mx.float32)\n",
    "        inp = mx.array(input, mx.float32)\n",
    "        \n",
    "        start_time = time.perf_counter()\n",
    "        mx.eval(matmul_mx(w, inp))\n",
    "        end_time = time.perf_counter()\n",
    "        del inp\n",
    "        del w\n",
    "        total_time += (end_time - start_time) * 1000\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_part1_mx(token_position, head, head_size, key_cache_layer, q):\n",
    "    return (mx.matmul(key_cache_layer[:token_position][:, (head) * (head_size):(head) * (head_size) + head_size], q[(head) * (head_size):(head) * (head_size) + head_size])) / (mx.sqrt(mx.array([(head_size) * (1)])))\n",
    "\n",
    "# def transformer_part1_runner(k_matrixes, q_matrixes, f=None):\n",
    "#     total_time = 0\n",
    "#     for i in range(len(k_matrixes)):\n",
    "#         k_matrix = k_matrixes[i]\n",
    "#         q_matrix = q_matrixes[i]\n",
    "#         token_position = k_matrix.shape[0] - 1\n",
    "\n",
    "#         num_head = 32\n",
    "#         head = int(rng.integers(low=0, high=num_head))\n",
    "#         head_size = k_matrix.shape[0] // num_head\n",
    "        \n",
    "#         key_cache_layer = mx.array(k_matrix, mx.float32)\n",
    "#         q = mx.array(q_matrix.flatten(), mx.float32)\n",
    "        \n",
    "#         start_time = time.perf_counter()\n",
    "#         mx.eval(transformer_part1_mx(token_position, head, head_size, key_cache_layer, q))\n",
    "#         end_time = time.perf_counter()\n",
    "#         del key_cache_layer\n",
    "#         del q\n",
    "#         total_time += (end_time - start_time) * 1000\n",
    "#     return total_time\n",
    "\n",
    "def transformer_part1_runner(k_matrixes, q_matrixes, f=None):\n",
    "    total_time = 0\n",
    "    for i in range(len(k_matrixes)):\n",
    "        k_matrix = k_matrixes[i].astype(np.float32)\n",
    "        q_matrix = q_matrixes[i].astype(np.float32)\n",
    "        token_position = k_matrix.shape[0] - 1\n",
    "\n",
    "        num_head = 32\n",
    "        head = int(rng.integers(low=0, high=num_head))\n",
    "        head_size = k_matrix.shape[0] // num_head\n",
    "        \n",
    "        key_cache_layer = mx.array(k_matrix, mx.float32)\n",
    "        q = mx.array(q_matrix.flatten(), mx.float32)\n",
    "        \n",
    "        start_time = time.perf_counter()\n",
    "        mx.eval(transformer_part1_mx(token_position, head, head_size, key_cache_layer, q))\n",
    "        end_time = time.perf_counter()\n",
    "        del key_cache_layer\n",
    "        del q\n",
    "        total_time += (end_time - start_time) * 1000\n",
    "    return total_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_part2_mx(token_position, head, head_size, key_cache_layer, attention):\n",
    "    return mx.matmul(mx.transpose(key_cache_layer[:(token_position) + (1)][:, (head) * (head_size):(head) * (head_size) + head_size]), attention[:(token_position) + (1)])\n",
    "\n",
    "# def transformer_part2_runner(k_matrixes, q_matrixes, f=None):\n",
    "#     total_time = 0\n",
    "#     for i in range(len(k_matrixes)):\n",
    "#         k_matrix = k_matrixes[i]\n",
    "#         q_matrix = q_matrixes[i]\n",
    "#         token_position = k_matrix.shape[0] - 1\n",
    "\n",
    "#         num_head = 32\n",
    "#         head = int(rng.integers(low=0, high=num_head))\n",
    "#         head_size = k_matrix.shape[0] // num_head\n",
    "        \n",
    "#         key_cache_layer = mx.array(k_matrix, mx.float32)\n",
    "#         q = mx.array(q_matrix.flatten(), mx.float32)\n",
    "\n",
    "#         attention = transformer_part1_mx(token_position, head, head_size, key_cache_layer, q)\n",
    "#         attention = mx.concatenate([attention, mx.array([0])])\n",
    "        \n",
    "#         start_time = time.perf_counter()\n",
    "#         mx.eval(transformer_part2_mx(token_position, head, head_size, key_cache_layer, attention))\n",
    "#         end_time = time.perf_counter()\n",
    "#         del key_cache_layer\n",
    "#         del attention\n",
    "#         total_time += (end_time - start_time) * 1000\n",
    "#     return total_time\n",
    "\n",
    "def transformer_part2_runner(k_matrixes, q_matrixes, f=None):\n",
    "    total_time = 0\n",
    "    for i in range(len(k_matrixes)):\n",
    "        k_matrix = k_matrixes[i].astype(np.float32)\n",
    "        q_matrix = q_matrixes[i].astype(np.float32)\n",
    "        token_position = k_matrix.shape[0] - 1\n",
    "\n",
    "        num_head = 32\n",
    "        head = int(rng.integers(low=0, high=num_head))\n",
    "        head_size = k_matrix.shape[0] // num_head\n",
    "        \n",
    "        key_cache_layer = mx.array(k_matrix, mx.float32)\n",
    "        q = mx.array(q_matrix.flatten(), mx.float32)\n",
    "\n",
    "        attention = transformer_part1_mx(token_position, head, head_size, key_cache_layer, q)\n",
    "        attention = mx.concatenate([attention, mx.array([0])])\n",
    "        \n",
    "        start_time = time.perf_counter()\n",
    "        mx.eval(transformer_part2_mx(token_position, head, head_size, key_cache_layer, attention))\n",
    "        end_time = time.perf_counter()\n",
    "        del key_cache_layer\n",
    "        del attention\n",
    "        total_time += (end_time - start_time) * 1000\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsnorm_part1_mx(input, weight):\n",
    "    return mx.sum((input) * (input))\n",
    "\n",
    "# def rmsnorm_part1_runner(weights, inputs, f=None):\n",
    "#     total_time = 0\n",
    "#     for i in range(len(inputs)):\n",
    "#         input = inputs[i].flatten()\n",
    "#         weight = weights[i].flatten()\n",
    "\n",
    "               \n",
    "#         inp = mx.array(input, mx.float32)\n",
    "#         w = mx.array(weight, mx.float32)\n",
    "\n",
    "#         start_time = time.perf_counter()\n",
    "#         mx.eval(rmsnorm_part1_mx(inp, w))\n",
    "#         end_time = time.perf_counter()\n",
    "#         del w\n",
    "#         del inp\n",
    "#         total_time += (end_time - start_time) * 1000\n",
    "#     return total_time\n",
    "\n",
    "def rmsnorm_part1_runner(weights, inputs, f=None):\n",
    "    total_time = 0\n",
    "    for i in range(len(inputs)):\n",
    "        input = inputs[i].flatten().astype(np.float32)\n",
    "        weight = weights[i].flatten().astype(np.float32)\n",
    "\n",
    "               \n",
    "        inp = mx.array(input, mx.float32)\n",
    "        w = mx.array(weight, mx.float32)\n",
    "\n",
    "        start_time = time.perf_counter()\n",
    "        mx.eval(rmsnorm_part1_mx(inp, w))\n",
    "        end_time = time.perf_counter()\n",
    "        del w\n",
    "        del inp\n",
    "        total_time += (end_time - start_time) * 1000\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsnorm_part2_mx(input, weight, ss):\n",
    "    return ((1) / (mx.sqrt(mx.array([((ss) / (input.size)) + (1)])))) * ((input) * (weight))\n",
    "\n",
    "# def rmsnorm_part2_runner(weights, inputs, f=None):\n",
    "#     total_time = 0\n",
    "#     for i in range(len(inputs)):\n",
    "#         input = inputs[i].flatten()\n",
    "#         weight = weights[i].flatten()\n",
    "#         ssum = np.sum(input * input)\n",
    "\n",
    "#         inp = mx.array(input, mx.float32)\n",
    "#         w = mx.array(weight, mx.float32)\n",
    "#         ss = mx.array(ssum, mx.float32)\n",
    "\n",
    "#         start_time = time.perf_counter()\n",
    "#         mx.eval(rmsnorm_part2_mx(inp, w, ss))\n",
    "#         end_time = time.perf_counter()\n",
    "#         del w\n",
    "#         del inp\n",
    "#         total_time += (end_time - start_time) * 1000\n",
    "#     return total_time\n",
    "\n",
    "def rmsnorm_part2_runner(weights, inputs, f=None):\n",
    "    total_time = 0\n",
    "    for i in range(len(inputs)):\n",
    "        input = inputs[i].flatten().astype(np.float32)\n",
    "        weight = weights[i].flatten().astype(np.float32)\n",
    "        ssum = np.sum(input * input)\n",
    "\n",
    "        inp = mx.array(input, mx.float32)\n",
    "        w = mx.array(weight, mx.float32)\n",
    "        ss = ssum\n",
    "        \n",
    "        start_time = time.perf_counter()\n",
    "        mx.eval(rmsnorm_part2_mx(inp, w, ss))\n",
    "        end_time = time.perf_counter()\n",
    "        del w\n",
    "        del inp\n",
    "        total_time += (end_time - start_time) * 1000\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_part3_mx(input, hidden_dim):\n",
    "    return (input[:hidden_dim]) * ((1) / ((1) + (mx.exp((0) - (input[:hidden_dim])))))\n",
    "\n",
    "# def transformer_part3_runner(inputs, _, f=None):\n",
    "#     total_time = 0\n",
    "#     for i in range(len(inputs)):\n",
    "#         input = inputs[i].flatten()\n",
    "#         hd = len(input)\n",
    "\n",
    "#         inp = mx.array(input, mx.float32)\n",
    "#         hidden_dim = hd\n",
    "#         start_time = time.perf_counter()\n",
    "#         mx.eval(transformer_part3_mx(inp, hidden_dim))\n",
    "#         end_time = time.perf_counter()\n",
    "#         del inp\n",
    "#         total_time += (end_time - start_time) * 1000\n",
    "#     return total_time\n",
    "\n",
    "def transformer_part3_runner(inputs, _, f=None):\n",
    "    total_time = 0\n",
    "    for i in range(len(inputs)):\n",
    "        input = inputs[i].flatten().astype(np.float32)\n",
    "        hd = len(input)\n",
    "\n",
    "        inp = mx.array(input, mx.float32)\n",
    "        hidden_dim = hd\n",
    "        start_time = time.perf_counter()\n",
    "        mx.eval(transformer_part3_mx(inp, hidden_dim))\n",
    "        end_time = time.perf_counter()\n",
    "        del inp\n",
    "        total_time += (end_time - start_time) * 1000\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_part1_mx(input, max_pos):\n",
    "    return mx.max(input[:max_pos])\n",
    "\n",
    "# def softmax_part1_runner(inputs, _, f=None):\n",
    "#     total_time = 0\n",
    "#     for i in range(len(inputs)):\n",
    "#         input = inputs[i].flatten()\n",
    "#         mp = len(input)\n",
    "        \n",
    "#         inp = mx.array(input, mx.float32)\n",
    "#         max_pos = mp\n",
    "#         start_time = time.perf_counter()\n",
    "#         mx.eval(softmax_part1_mx(inp, max_pos))\n",
    "#         end_time = time.perf_counter()\n",
    "#         del inp\n",
    "#         total_time += (end_time - start_time) * 1000\n",
    "#     return total_time\n",
    "\n",
    "def softmax_part1_runner(inputs, _, f=None):\n",
    "    total_time = 0\n",
    "    for i in range(len(inputs)):\n",
    "        input = inputs[i].flatten().astype(np.float32)\n",
    "        mp = len(input)\n",
    "        \n",
    "        inp = mx.array(input, mx.float32)\n",
    "        max_pos = mp\n",
    "        start_time = time.perf_counter()\n",
    "        mx.eval(softmax_part1_mx(inp, max_pos))\n",
    "        end_time = time.perf_counter()\n",
    "        del inp\n",
    "        total_time += (end_time - start_time) * 1000\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_part2_mx(input, max_pos, max_val):\n",
    "    return mx.exp((input[:max_pos]) - (max_val))\n",
    "\n",
    "# def softmax_part2_runner(inputs, _, f=None):\n",
    "#     total_time = 0\n",
    "#     for i in range(len(inputs)):\n",
    "#         input = inputs[i].flatten()\n",
    "#         mp = len(input)\n",
    "        \n",
    "#         inp = mx.array(input, mx.float32)\n",
    "#         max_pos = mp\n",
    "#         max_val = mx.array(np.max(input[:mp]), mx.float32)\n",
    "\n",
    "#         start_time = time.perf_counter()\n",
    "#         mx.eval(softmax_part2_mx(inp, max_pos, max_val))\n",
    "#         end_time = time.perf_counter()\n",
    "#         del inp\n",
    "#         total_time += (end_time - start_time) * 1000\n",
    "#     return total_time\n",
    "\n",
    "def softmax_part2_runner(inputs, _, f=None):\n",
    "    total_time = 0\n",
    "    for i in range(len(inputs)):\n",
    "        input = inputs[i].flatten().astype(np.float32)\n",
    "        mp = len(input)\n",
    "        \n",
    "        inp = mx.array(input, mx.float32)\n",
    "        max_pos = mp\n",
    "        max_val = mx.array(np.max(input[:mp]), mx.float32)\n",
    "\n",
    "        start_time = time.perf_counter()\n",
    "        mx.eval(softmax_part2_mx(inp, max_pos, max_val))\n",
    "        end_time = time.perf_counter()\n",
    "        del inp\n",
    "        total_time += (end_time - start_time) * 1000\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_part3_mx(output, max_pos):\n",
    "    return mx.sum(output[:max_pos])\n",
    "\n",
    "# def softmax_part3_runner(inputs, _, f=None):\n",
    "#     total_time = 0\n",
    "#     for i in range(len(inputs)):\n",
    "#         input = inputs[i].flatten()\n",
    "#         mp = len(input)\n",
    "#         output = np.exp(input[:mp]-np.max(input[:mp]))\n",
    "        \n",
    "#         outp = mx.array(output, mx.float32)\n",
    "#         max_pos = mp\n",
    "        \n",
    "#         start_time = time.perf_counter()\n",
    "#         mx.eval(softmax_part3_mx(outp, max_pos))\n",
    "#         end_time = time.perf_counter()\n",
    "#         del outp\n",
    "#         total_time += (end_time - start_time) * 1000\n",
    "#     return total_time\n",
    "\n",
    "def softmax_part3_runner(inputs, _, f=None):\n",
    "    total_time = 0\n",
    "    for i in range(len(inputs)):\n",
    "        input = inputs[i].flatten().astype(np.float32)\n",
    "        mp = len(input)\n",
    "        output = np.exp(input[:mp]-np.max(input[:mp]))\n",
    "        \n",
    "        outp = mx.array(output, mx.float32)\n",
    "        max_pos = mp\n",
    "        \n",
    "        start_time = time.perf_counter()\n",
    "        mx.eval(softmax_part3_mx(outp, max_pos))\n",
    "        end_time = time.perf_counter()\n",
    "        del outp\n",
    "        total_time += (end_time - start_time) * 1000\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_part4_mx(unnormalized_output, max_pos, sum):\n",
    "    return (unnormalized_output[:max_pos]) / (sum)\n",
    "\n",
    "# def softmax_part4_runner(inputs, _, f=None):\n",
    "#     total_time = 0\n",
    "#     for i in range(len(inputs)):\n",
    "#         input = inputs[i].flatten()\n",
    "#         mp = len(input)\n",
    "#         output = np.exp(input[:mp]-np.max(input[:mp]))\n",
    "#         s = np.sum(output[:mp])\n",
    "        \n",
    "#         outp = mx.array(output, mx.float32)\n",
    "#         max_pos = mp\n",
    "#         sum = mx.array(s, mx.float32)\n",
    "        \n",
    "#         start_time = time.perf_counter()\n",
    "#         mx.eval(softmax_part4_mx(outp, max_pos, sum))\n",
    "#         end_time = time.perf_counter()\n",
    "#         del outp\n",
    "#         total_time += (end_time - start_time) * 1000\n",
    "#     return total_time\n",
    "\n",
    "def softmax_part4_runner(inputs, _, f=None):\n",
    "    total_time = 0\n",
    "    for i in range(len(inputs)):\n",
    "        input = inputs[i].flatten().astype(np.float32)\n",
    "        mp = len(input)\n",
    "        output = np.exp(input[:mp]-np.max(input[:mp]))\n",
    "        s = np.sum(output[:mp])\n",
    "        \n",
    "        outp = mx.array(output, mx.float32)\n",
    "        max_pos = mp\n",
    "        sum = mx.array(s, mx.float32)\n",
    "        \n",
    "        start_time = time.perf_counter()\n",
    "        mx.eval(softmax_part4_mx(outp, max_pos, sum))\n",
    "        end_time = time.perf_counter()\n",
    "        del outp\n",
    "        total_time += (end_time - start_time) * 1000\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elewise_mul_mlx\n",
      "124.46504530007587ms +/- 9.615869981105703ms\n"
     ]
    }
   ],
   "source": [
    "timer(weights, w_input, None, transformer_part4_runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matmul_mlx\n",
      "26.145453799381357ms +/- 1.4911706287728572ms\n"
     ]
    }
   ],
   "source": [
    "timer(attn_weights, aw_input, None, matmul_runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiquery_attention_part1_mlx\n",
      "9.95410899977287ms +/- 16.71460224299404ms\n"
     ]
    }
   ],
   "source": [
    "timer(k_weights, q_weights, None, transformer_part1_runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiquery_attention_part2_mlx\n",
      "9.576474699770188ms +/- 13.601878665346964ms\n"
     ]
    }
   ],
   "source": [
    "timer(k_weights, q_weights, None, transformer_part2_runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmsnorm_part1_mlx\n",
      "151.8911950999609ms +/- 23.116388873278304ms\n"
     ]
    }
   ],
   "source": [
    "timer(weights, w_input, None, rmsnorm_part1_runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmsnorm_part2_mlx\n",
      "187.68991289998667ms +/- 14.889146486184822ms\n"
     ]
    }
   ],
   "source": [
    "timer(weights, w_input,None, rmsnorm_part2_runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "silu_mlx\n",
      "324.14364539918097ms +/- 15.11308505256706ms\n"
     ]
    }
   ],
   "source": [
    "timer(weights, None, None, transformer_part3_runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax_part1_mlx\n",
      "34.38897890046064ms +/- 3.784112471945636ms\n"
     ]
    }
   ],
   "source": [
    "timer(attn_weights, None, None, softmax_part1_runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax_part2_mlx\n",
      "64.34085259943458ms +/- 1.6587003885597416ms\n"
     ]
    }
   ],
   "source": [
    "timer(attn_weights, None, None, softmax_part2_runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax_part3_mlx\n",
      "37.81613349892723ms +/- 0.938680863344943ms\n"
     ]
    }
   ],
   "source": [
    "timer(attn_weights, None, None, softmax_part3_runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax_part4_mlx\n",
      "65.29268749991388ms +/- 9.300468336661075ms\n"
     ]
    }
   ],
   "source": [
    "timer(attn_weights, None, None, softmax_part4_runner)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
