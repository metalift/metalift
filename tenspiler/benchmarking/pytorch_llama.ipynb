{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/c/miniconda3/envs/cs285/lib/python3.10/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(1)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = './vicuna_weight.h5'\n",
    "\n",
    "weights = []\n",
    "w_input = []\n",
    "attn_weights = []\n",
    "aw_input = []\n",
    "q_weights = []\n",
    "k_weights = []\n",
    "\n",
    "with h5py.File(weights_path, 'r') as weight_file:\n",
    "    for layer_name in weight_file:\n",
    "        w = np.squeeze(np.array(weight_file[layer_name])).astype(np.float32)\n",
    "        if \"model\" in layer_name and \"embed_tokens\" not in layer_name and \"layernorm\" not in layer_name:\n",
    "            weights.append(w)\n",
    "            w_input.append(rng.random(w.shape, dtype = np.float32))\n",
    "        if \"attn\" in layer_name:\n",
    "            attn_weights.append(w)\n",
    "            aw_input.append(rng.random(w.shape[1], dtype = np.float32))\n",
    "            if \"q_proj\" in layer_name:\n",
    "                q_weights.append(w)\n",
    "            if \"k_proj\" in layer_name:\n",
    "                k_weights.append(w)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer(input1, input2, f, runner):\n",
    "    runs = 10\n",
    "    times = []\n",
    "    for _ in range(runs):\n",
    "        times.append(runner(input1, input2, f))\n",
    "    times = np.array(times)\n",
    "    print(f\"{runner.__name__[:-6]}pytorch\")\n",
    "    print(f\"{np.average(times)}ms +/- {np.std(times)}ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_part4_torch(input1, input2, hidden_dim):\n",
    "    return (input1[:hidden_dim]) * (input2[:hidden_dim])\n",
    "\n",
    "def transformer_part4_runner(inputs1, inputs2, f=None):\n",
    "    total_time = 0\n",
    "    for i in range(len(inputs1)):\n",
    "        input1 = inputs1[i].flatten()\n",
    "        input2 = inputs2[i].flatten()\n",
    "        hd = len(input1)\n",
    "\n",
    "        inp1 = torch.from_numpy(input1).to(dtype=torch.float32).to(device)\n",
    "        inp2 = torch.from_numpy(input2).to(dtype=torch.float32).to(device)\n",
    "        hidden_dim = torch.tensor(hd).to(device)\n",
    "        \n",
    "        start_time = time.perf_counter()\n",
    "        transformer_part4_torch(inp1, inp2, hidden_dim)\n",
    "        end_time = time.perf_counter()\n",
    "        del inp2\n",
    "        del inp1\n",
    "        total_time += (end_time - start_time) * 1000\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul_torch(weight, input):\n",
    "    return torch.matmul(weight, input)\n",
    "\n",
    "def matmul_runner(weights, inputs, f=None):\n",
    "    total_time = 0\n",
    "    for i in range(len(inputs)):\n",
    "        weight = weights[i]\n",
    "        input = inputs[i]\n",
    "\n",
    "        w = torch.from_numpy(weight).to(dtype=torch.float32).to(device)\n",
    "        inp = torch.from_numpy(input).to(dtype=torch.float32).to(device)\n",
    "        \n",
    "        start_time = time.perf_counter()\n",
    "        matmul_torch(w, inp)\n",
    "        end_time = time.perf_counter()\n",
    "        del inp\n",
    "        del w\n",
    "        total_time += (end_time - start_time) * 1000\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_part1_torch(token_position, head, head_size, key_cache_layer, q):\n",
    "    return (torch.matmul(key_cache_layer[:token_position][:, (head) * (head_size):(head) * (head_size) + head_size], q[(head) * (head_size):(head) * (head_size) + head_size])) / (torch.sqrt(torch.as_tensor((head_size) * (1))))\n",
    "\n",
    "def transformer_part1_runner(k_matrixes, q_matrixes, f=None):\n",
    "    total_time = 0\n",
    "    for i in range(len(k_matrixes)):\n",
    "        k_matrix = k_matrixes[i]\n",
    "        q_matrix = q_matrixes[i]\n",
    "        token_position = k_matrix.shape[0] - 1\n",
    "\n",
    "        num_head = 32\n",
    "        head = int(rng.integers(low=0, high=num_head))\n",
    "        head_size = k_matrix.shape[0] // num_head\n",
    "        \n",
    "        key_cache_layer = torch.from_numpy(k_matrix).to(device)\n",
    "        q = torch.from_numpy(q_matrix.flatten()).to(device)\n",
    "        \n",
    "        start_time = time.perf_counter()\n",
    "        transformer_part1_torch(token_position, head, head_size, key_cache_layer, q)\n",
    "        end_time = time.perf_counter()\n",
    "        del key_cache_layer\n",
    "        del q\n",
    "        total_time += (end_time - start_time) * 1000\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_part2_torch(token_position, head, head_size, key_cache_layer, attention):\n",
    "    return torch.matmul(torch.transpose(key_cache_layer[:(token_position) + (1)][:, (head) * (head_size):(head) * (head_size) + head_size], 0, 1), attention[:(token_position) + (1)])\n",
    "\n",
    "def transformer_part2_runner(k_matrixes, q_matrixes, f=None):\n",
    "    total_time = 0\n",
    "    for i in range(len(k_matrixes)):\n",
    "        k_matrix = k_matrixes[i]\n",
    "        q_matrix = q_matrixes[i]\n",
    "        token_position = k_matrix.shape[0] - 1\n",
    "\n",
    "        num_head = 32\n",
    "        head = int(rng.integers(low=0, high=num_head))\n",
    "        head_size = k_matrix.shape[0] // num_head\n",
    "        \n",
    "        key_cache_layer = torch.from_numpy(k_matrix).to(device)\n",
    "        q = torch.from_numpy(q_matrix.flatten()).to(device)\n",
    "\n",
    "        attention = transformer_part1_torch(token_position, head, head_size, key_cache_layer, q).to(device)\n",
    "        attention = torch.cat((attention, torch.tensor([0]).to(device))).to(device)\n",
    "        \n",
    "        start_time = time.perf_counter()\n",
    "        transformer_part2_torch(token_position, head, head_size, key_cache_layer, attention)\n",
    "        end_time = time.perf_counter()\n",
    "        del key_cache_layer\n",
    "        del attention\n",
    "        total_time += (end_time - start_time) * 1000\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsnorm_part1_torch(input, weight):\n",
    "    return torch.sum((input) * (input))\n",
    "\n",
    "def rmsnorm_part1_runner(weights, inputs, f=None):\n",
    "    total_time = 0\n",
    "    for i in range(len(inputs)):\n",
    "        input = inputs[i].flatten()\n",
    "        weight = weights[i].flatten()\n",
    "        \n",
    "        inp = torch.from_numpy(input).to(dtype=torch.float32).to(device)\n",
    "        w = torch.from_numpy(weight).to(dtype=torch.float32).to(device)\n",
    "        start_time = time.perf_counter()\n",
    "        rmsnorm_part1_torch(inp, w)\n",
    "        end_time = time.perf_counter()\n",
    "        del w\n",
    "        del inp\n",
    "        total_time += (end_time - start_time) * 1000\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsnorm_part2_torch(input, weight, ss):\n",
    "    return ((1) / (torch.sqrt(torch.as_tensor(((ss) / (input.size(dim=0))) + (1))))) * ((input) * (weight))\n",
    "\n",
    "def rmsnorm_part2_runner(weights, inputs, f=None):\n",
    "    total_time = 0\n",
    "    for i in range(len(inputs)):\n",
    "        input = inputs[i].flatten()\n",
    "        weight = weights[i].flatten()\n",
    "        ssum = np.sum(input * input)\n",
    "\n",
    "        inp = torch.from_numpy(input).to(dtype=torch.float32).to(device)\n",
    "        w = torch.from_numpy(weight).to(dtype=torch.float32).to(device)\n",
    "        ss = torch.tensor(ssum).to(dtype=torch.float32).to(device)\n",
    "\n",
    "        start_time = time.perf_counter()\n",
    "        rmsnorm_part2_torch(inp, w, ss)\n",
    "        end_time = time.perf_counter()\n",
    "        del w\n",
    "        del inp\n",
    "        total_time += (end_time - start_time) * 1000\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_part3_torch(input, hidden_dim):\n",
    "    return (input[:hidden_dim]) * ((1) / ((1) + (torch.exp(torch.as_tensor((0) - (input[:hidden_dim]))))))\n",
    "\n",
    "def transformer_part3_runner(inputs, _, f=None):\n",
    "    total_time = 0\n",
    "    for i in range(len(inputs)):\n",
    "        input = inputs[i].flatten()\n",
    "        hd = len(input)\n",
    "\n",
    "        inp = torch.from_numpy(input).to(dtype=torch.float32).to(device)\n",
    "        hidden_dim = torch.tensor(hd).to(device)\n",
    "        start_time = time.perf_counter()\n",
    "        transformer_part3_torch(inp, hidden_dim)\n",
    "        end_time = time.perf_counter()\n",
    "        del inp\n",
    "        total_time += (end_time - start_time) * 1000\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_part1_torch(input, max_pos):\n",
    "    return torch.max(input[:max_pos])\n",
    "\n",
    "def softmax_part1_runner(inputs, _, f=None):\n",
    "    total_time = 0\n",
    "    for i in range(len(inputs)):\n",
    "        input = inputs[i].flatten()\n",
    "        mp = len(input)\n",
    "        \n",
    "        inp = torch.from_numpy(input).to(device)\n",
    "        max_pos = torch.tensor(mp).to(device)\n",
    "        start_time = time.perf_counter()\n",
    "        softmax_part1_torch(inp, max_pos)\n",
    "        end_time = time.perf_counter()\n",
    "        del inp\n",
    "        total_time += (end_time - start_time) * 1000\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_part2_torch(input, max_pos, max_val):\n",
    "    return torch.exp(torch.as_tensor((input[:max_pos]) - (max_val)))\n",
    "\n",
    "def softmax_part2_runner(inputs, _, f=None):\n",
    "    total_time = 0\n",
    "    for i in range(len(inputs)):\n",
    "        input = inputs[i].flatten()\n",
    "        mp = len(input)\n",
    "        \n",
    "        inp = torch.from_numpy(input).to(dtype=torch.float32).to(device)\n",
    "        max_pos = torch.tensor(mp).to(device)\n",
    "        max_val = torch.tensor(np.max(input[:mp])).to(dtype=torch.float32).to(device)\n",
    "\n",
    "        start_time = time.perf_counter()\n",
    "        softmax_part2_torch(inp, max_pos, max_val)\n",
    "        end_time = time.perf_counter()\n",
    "        del inp\n",
    "        total_time += (end_time - start_time) * 1000\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_part3_torch(output, max_pos):\n",
    "    return torch.sum(output[:max_pos])\n",
    "\n",
    "def softmax_part3_runner(inputs, _, f=None):\n",
    "    total_time = 0\n",
    "    for i in range(len(inputs)):\n",
    "        input = inputs[i].flatten()\n",
    "        mp = len(input)\n",
    "        output = np.exp(input[:mp]-np.max(input[:mp]))\n",
    "        \n",
    "        outp = torch.from_numpy(output).to(dtype=torch.float32).to(device)\n",
    "        max_pos = torch.tensor(mp).to(device)\n",
    "        \n",
    "        start_time = time.perf_counter()\n",
    "        softmax_part3_torch(outp, max_pos)\n",
    "        end_time = time.perf_counter()\n",
    "        del outp\n",
    "        total_time += (end_time - start_time) * 1000\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_part4_torch(unnormalized_output, max_pos, sum):\n",
    "    return (unnormalized_output[:max_pos]) / (sum)\n",
    "\n",
    "def softmax_part4_runner(inputs, _, f=None):\n",
    "    total_time = 0\n",
    "    for i in range(len(inputs)):\n",
    "        input = inputs[i].flatten()\n",
    "        mp = len(input)\n",
    "        output = np.exp(input[:mp]-np.max(input[:mp]))\n",
    "        s = np.sum(output[:mp])\n",
    "        \n",
    "        outp = torch.from_numpy(output).to(dtype=torch.float32).to(device)\n",
    "        max_pos = torch.tensor(mp).to(device)\n",
    "        sum = torch.tensor(s).to(dtype=torch.float32).to(device)\n",
    "        \n",
    "        start_time = time.perf_counter()\n",
    "        softmax_part4_torch(outp, max_pos, sum)\n",
    "        end_time = time.perf_counter()\n",
    "        del outp\n",
    "        total_time += (end_time - start_time) * 1000\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer(weights, w_input, None, transformer_part4_runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matmul_pytorch\n",
      "24.433968123048544ms +/- 1.381028715149651ms\n"
     ]
    }
   ],
   "source": [
    "timer(attn_weights, aw_input, None, matmul_runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiquery_attention_part1_pytorch\n",
      "1.2479783035814762ms +/- 1.318031165149219ms\n"
     ]
    }
   ],
   "source": [
    "timer(k_weights, q_weights, None, transformer_part1_runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiquery_attention_part2_pytorch\n",
      "0.2821787726134062ms +/- 0.18459898719304943ms\n"
     ]
    }
   ],
   "source": [
    "timer(k_weights, q_weights, None, transformer_part2_runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmsnorm_part1_pytorch\n",
      "454.0018748957664ms +/- 0.7874046614157534ms\n"
     ]
    }
   ],
   "source": [
    "timer(weights, w_input, None, rmsnorm_part1_runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmsnorm_part2_pytorch\n",
      "766.2844286300242ms +/- 3.051371663684736ms\n"
     ]
    }
   ],
   "source": [
    "timer(weights, w_input,None, rmsnorm_part2_runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "silu_pytorch\n",
      "1947.5853705778718ms +/- 5.557897591486259ms\n"
     ]
    }
   ],
   "source": [
    "timer(weights, None, None, transformer_part3_runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax_part1_pytorch\n",
      "27.303209900856018ms +/- 0.14051284226447797ms\n"
     ]
    }
   ],
   "source": [
    "timer(attn_weights, None, None, softmax_part1_runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax_part2_pytorch\n",
      "237.33236687257886ms +/- 0.7364762389287917ms\n"
     ]
    }
   ],
   "source": [
    "timer(attn_weights, None, None, softmax_part2_runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax_part3_pytorch\n",
      "24.55094694159925ms +/- 0.2237995992287591ms\n"
     ]
    }
   ],
   "source": [
    "timer(attn_weights, None, None, softmax_part3_runner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax_part4_pytorch\n",
      "149.70479435287416ms +/- 0.17329120919903354ms\n"
     ]
    }
   ],
   "source": [
    "timer(attn_weights, None, None, softmax_part4_runner)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs285",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
