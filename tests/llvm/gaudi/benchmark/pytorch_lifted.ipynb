{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3Fcj9JH7G-0j"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import time\n",
        "import cv2\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zLxZyGubTtrb"
      },
      "outputs": [],
      "source": [
        "### PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Bvs7Taz9RSF6"
      },
      "outputs": [],
      "source": [
        "### Nested"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5sW8bFYRUsGm"
      },
      "outputs": [],
      "source": [
        "def darken_blend_8_torch(base, active):\n",
        "  return torch.where(torch.greater(base, active), active, base)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LhofMRejUsKe"
      },
      "outputs": [],
      "source": [
        "def color_burn_8_torch(base, active):\n",
        "  return torch.where(torch.eq(active, 0.0), 255.0, 255.0 - (255.0 - base) / active)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "oQHTB_4WUsPS"
      },
      "outputs": [],
      "source": [
        "def lighten_blend_8_torch(base, active):\n",
        "  return torch.where(torch.less(base, active), active, base)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "iGDkMUhlUsT5"
      },
      "outputs": [],
      "source": [
        "def color_dodge_8_torch(base, active):\n",
        "  return torch.where(torch.eq(active, 255.0), 255.0, base / (255.0 - active))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "u5ABMdg-UsYn"
      },
      "outputs": [],
      "source": [
        "def overlay_blend_8_torch(base, active):\n",
        "  return torch.where(torch.greater_equal(base, 128.0), 2 * base + base - 2 * base * base / 255.0 - 128.0, 2 * base * base / 128.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "EErCwOeTUsc8"
      },
      "outputs": [],
      "source": [
        "def multiply_blend_8_torch(base, active):\n",
        "  return base * active / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "8iGd1h1gUsg1"
      },
      "outputs": [],
      "source": [
        "def linear_burn_8_torch(base, active):\n",
        "  return base + active - 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0qt2hYdeUslS"
      },
      "outputs": [],
      "source": [
        "def screen_blend_8_torch(base, active):\n",
        "  return base + active - base * active / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "nudlnaGjUsrK"
      },
      "outputs": [],
      "source": [
        "def linear_dodge_8_torch(base, active):\n",
        "  return base + active"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ZmB47LCHYCBS"
      },
      "outputs": [],
      "source": [
        "### Single"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "KfFDKDECRXAI"
      },
      "outputs": [],
      "source": [
        "def normal_blend_f_torch(base, active, opacity):\n",
        "  return opacity * active + (1-opacity)*base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "xf1U5M15RXCv"
      },
      "outputs": [],
      "source": [
        "def normal_blend_8_torch(base, active, opacity):\n",
        "  return opacity * active + (255.0 - opacity) * base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bV44qa89RXFD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "pdEC-wgZYCDV"
      },
      "outputs": [],
      "source": [
        "### Runner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "HyrZAHwYYDWc"
      },
      "outputs": [],
      "source": [
        "rng = np.random.default_rng(1)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "folder = \"./data/\"\n",
        "\n",
        "img_files = [os.path.join(folder, f) for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))]\n",
        "\n",
        "bases = []\n",
        "actives = []\n",
        "\n",
        "for _file in img_files:\n",
        "    img = cv2.imread(_file, cv2.IMREAD_GRAYSCALE)\n",
        "    rnd = rng.random(img.shape, dtype = np.float32) * 255\n",
        "    bases.append(img)\n",
        "    actives.append(rnd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "def mat_runner(bases, actives, f):\n",
        "    total_time = 0\n",
        "    for i in range(len(bases)):\n",
        "        b = torch.from_numpy(bases[i]).to(device)\n",
        "        a = torch.from_numpy(actives[i]).to(device)\n",
        "        start_time = time.perf_counter()\n",
        "        f(b, a)\n",
        "        end_time = time.perf_counter()\n",
        "        del a\n",
        "        del b\n",
        "        total_time += (end_time - start_time) * 1000\n",
        "    return total_time\n",
        "\n",
        "def vec_runner(bases, actives, f):\n",
        "    total_time = 0\n",
        "    for i in range(len(bases)):\n",
        "        base = bases[i].flatten()\n",
        "        active = actives[i].flatten()\n",
        "        b = torch.from_numpy(base).to(device)\n",
        "        a = torch.from_numpy(active).to(device)\n",
        "        opacity = torch.from_numpy(rng.random(1, dtype = np.float32)).to(device)\n",
        "        start_time = time.perf_counter()\n",
        "        f(b, a, opacity)\n",
        "        end_time = time.perf_counter()\n",
        "        del a\n",
        "        del b\n",
        "        total_time += (end_time - start_time) * 1000\n",
        "    return total_time\n",
        "\n",
        "def timer(bases, actives, f, runner):\n",
        "    runs = 5\n",
        "    times = []\n",
        "    for _ in range(runs):\n",
        "        times.append(runner(bases, actives, f))\n",
        "    times = np.array(times)\n",
        "    print(f\"{np.average(times)}ms +/- {np.std(times)}ms\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKkcjRA0YmzU",
        "outputId": "27860dd5-35e7-47eb-dc1e-4938eeb8228a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "95.14127150177956ms +/- 9.552276584996ms\n"
          ]
        }
      ],
      "source": [
        "timer(bases, actives, darken_blend_8_torch, mat_runner)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w10sRAzDYoGT",
        "outputId": "26ea9977-2372-489b-8065-a8742e0b8ae8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "203.40639874339104ms +/- 9.176950285843265ms\n"
          ]
        }
      ],
      "source": [
        "timer(bases, actives, color_burn_8_torch, mat_runner)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aA7sz7X6YoJO",
        "outputId": "6ba40a4f-490a-4980-ddec-46063f70c438"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "91.59864517860115ms +/- 0.21304854932706857ms\n"
          ]
        }
      ],
      "source": [
        "timer(bases, actives, lighten_blend_8_torch, mat_runner)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFkhLQ-bYoLn",
        "outputId": "5724d50e-371e-4a8d-e730-254298c4fc67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "168.6593317426741ms +/- 1.4745537085521756ms\n"
          ]
        }
      ],
      "source": [
        "timer(bases, actives, color_dodge_8_torch, mat_runner)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIahWffgYoN_",
        "outputId": "9fbc19db-77ad-4278-8365-6a923b20855e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "356.2803265172988ms +/- 2.394989602959726ms\n"
          ]
        }
      ],
      "source": [
        "timer(bases, actives, overlay_blend_8_torch, mat_runner)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwZqD1uQYoQQ",
        "outputId": "6d4246b4-4264-463f-99bb-e4a89f19e2bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "64.6401193458587ms +/- 0.5352644389666419ms\n"
          ]
        }
      ],
      "source": [
        "timer(bases, actives, multiply_blend_8_torch, mat_runner)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rE3ASPNsYoSy",
        "outputId": "04521810-5d62-4282-d342-d2cf717e1a1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "64.94646281935275ms +/- 0.30916351829087185ms\n"
          ]
        }
      ],
      "source": [
        "timer(bases, actives, linear_burn_8_torch, mat_runner)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRNbIvPnYoVY",
        "outputId": "48de1a07-c5e8-4c11-9b5a-650891d40088"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "116.02817266248167ms +/- 0.11179207061911214ms\n"
          ]
        }
      ],
      "source": [
        "timer(bases, actives, screen_blend_8_torch, mat_runner)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fs1-_RliYoYK",
        "outputId": "855991bc-b3d1-4324-99e9-6b02e24bef5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "31.87446901574731ms +/- 0.4331737883674408ms\n"
          ]
        }
      ],
      "source": [
        "timer(bases, actives, linear_dodge_8_torch, mat_runner)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_D_lZp-USVO",
        "outputId": "0191c9b5-e64f-437b-ab6e-a400e31dc7a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "142.37591503188014ms +/- 1.3606784973507235ms\n"
          ]
        }
      ],
      "source": [
        "timer(bases, actives, normal_blend_f_torch, vec_runner)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gpc8nUKlUSXa",
        "outputId": "06442fad-0fb3-43be-ca67-79a398debbf5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "142.80818467959762ms +/- 0.7610048509636361ms\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "timer(bases, actives, normal_blend_8_torch, vec_runner)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
